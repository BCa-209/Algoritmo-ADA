# busqueda_dfs_bfs.py
import pandas as pd
import networkx as nx
import os
import re
from datetime import datetime

def cargar_arbol_enraizado(ruta_archivo):
    """
    Carga el √°rbol enraizado desde archivo GML
    """
    try:
        arbol = nx.read_gml(ruta_archivo)
        nombre_archivo = os.path.basename(ruta_archivo)
        nombre_grafo = nombre_archivo.replace('.gml', '')
        
        print(f"√Årbol enraizado cargado: {nombre_grafo}")
        print(f"  Nodos: {arbol.number_of_nodes()}")
        print(f"  Aristas: {arbol.number_of_edges()}")
        
        return arbol, nombre_grafo
    except Exception as e:
        print(f"Error cargando {ruta_archivo}: {e}")
        return None, None

def extraer_configuracion_archivo(nombre_archivo):
    """
    Extrae la configuraci√≥n (B4C, W2C, etc.) del nombre del archivo
    """
    # Patrones para detectar la configuraci√≥n
    patrones = [
        r'(B|W)(\d+)C',  # B4C, W2C, etc.
        r'reducido_(B|W)(\d+)C',  # arbol_reducido_B4C...
        r'enraizado_(B|W)(\d+)C'  # arbol_enraizado_B4C...
    ]
    
    for patron in patrones:
        match = re.search(patron, nombre_archivo)
        if match:
            tipo = match.group(1)  # B o W
            qrtl = match.group(2)  # 2, 4, 8, 16
            return f"{tipo}{qrtl}C"
    
    # Si no encuentra patr√≥n, usar el nombre del archivo sin extensi√≥n
    return nombre_archivo.replace('.gml', '')

def encontrar_nodo_raiz(arbol):
    """
    Encuentra el nodo ra√≠z del √°rbol (nodo con grado de entrada 0)
    """
    raices = [nodo for nodo in arbol.nodes() if arbol.in_degree(nodo) == 0]
    if raices:
        return raices[0]
    else:
        # Si no hay nodo con grado de entrada 0, buscar el que tiene m√°s conexiones
        return max(arbol.nodes(), key=lambda x: arbol.out_degree(x))

def busqueda_anchura_limitada(arbol, nodo_inicio, limite_nivel=3):
    """
    Realiza b√∫squeda en anchura (BFS) desde el nodo inicial con l√≠mite de niveles
    """
    print(f"\n" + "="*50)
    print(f"B√öSQUEDA EN ANCHURA (BFS) - Desde: {nodo_inicio} - L√≠mite: {limite_nivel} niveles")
    print("="*50)
    
    visitados = set()
    cola = [nodo_inicio]
    orden_bfs = []
    niveles = {}
    nivel_actual = 0
    nodos_por_nivel = {nivel_actual: [nodo_inicio]}
    
    while cola and nivel_actual < limite_nivel:
        siguiente_nivel = []
        
        for nodo_actual in cola:
            if nodo_actual not in visitados:
                visitados.add(nodo_actual)
                orden_bfs.append(nodo_actual)
                
                # Obtener sucesores (hijos) del nodo actual
                sucesores = list(arbol.successors(nodo_actual))
                siguiente_nivel.extend(sucesores)
                
                if sucesores:
                    nodos_por_nivel[nivel_actual + 1] = nodos_por_nivel.get(nivel_actual + 1, []) + sucesores
        
        cola = siguiente_nivel
        nivel_actual += 1
    
    # Mostrar resultados
    print(f"Orden de visita BFS (limitado a {limite_nivel} niveles):")
    print(f"{' ‚Üí '.join(orden_bfs)}")
    print(f"Total de nodos visitados: {len(orden_bfs)}")
    
    print(f"\nEstructura por niveles (hasta nivel {limite_nivel}):")
    for nivel in range(min(limite_nivel + 1, len(nodos_por_nivel))):
        if nivel in nodos_por_nivel and nodos_por_nivel[nivel]:
            print(f"  Nivel {nivel}: {nodos_por_nivel[nivel]}")
    
    return orden_bfs, nodos_por_nivel

def busqueda_profundidad_limitada(arbol, nodo_inicio, limite_profundidad=3):
    """
    Realiza b√∫squeda en profundidad (DFS) desde el nodo inicial con l√≠mite de profundidad
    """
    print(f"\n" + "="*50)
    print(f"B√öSQUEDA EN PROFUNDIDAD (DFS) - Desde: {nodo_inicio} - L√≠mite: {limite_profundidad} niveles")
    print("="*50)
    
    visitados = set()
    orden_dfs = []
    caminos_completos = []
    
    def dfs_recursivo(nodo_actual, camino_actual, profundidad_actual):
        # Si superamos el l√≠mite de profundidad, detener la recursi√≥n
        if profundidad_actual > limite_profundidad:
            return
        
        if nodo_actual not in visitados:
            visitados.add(nodo_actual)
            camino_actual.append(nodo_actual)
            orden_dfs.append(nodo_actual)
            
            # Obtener sucesores (hijos)
            sucesores = list(arbol.successors(nodo_actual))
            
            if not sucesores or profundidad_actual == limite_profundidad:  # Es una hoja o l√≠mite alcanzado
                caminos_completos.append(camino_actual.copy())
                print(f"  Camino (profundidad {profundidad_actual}): {' ‚Üí '.join(camino_actual)}")
            else:
                for sucesor in sucesores:
                    dfs_recursivo(sucesor, camino_actual.copy(), profundidad_actual + 1)
    
    dfs_recursivo(nodo_inicio, [], 0)
    
    # Mostrar resultados
    print(f"\nOrden de visita DFS (limitado a {limite_profundidad} niveles):")
    print(f"{' ‚Üí '.join(orden_dfs)}")
    print(f"Total de nodos visitados: {len(orden_dfs)}")
    print(f"Caminos completos encontrados: {len(caminos_completos)}")
    
    return orden_dfs, caminos_completos

def analizar_estructura_arbol(arbol, nodo_raiz):
    """
    Analiza la estructura completa del √°rbol
    """
    print(f"\n" + "="*60)
    print(f"AN√ÅLISIS COMPLETO DEL √ÅRBOL - Ra√≠z: {nodo_raiz}")
    print("="*60)
    
    # Informaci√≥n b√°sica
    print(f"Informaci√≥n del √°rbol:")
    print(f"  - Total de nodos: {arbol.number_of_nodes()}")
    print(f"  - Total de aristas: {arbol.number_of_edges()}")
    print(f"  - Nodo ra√≠z: {nodo_raiz}")
    
    # Calcular profundidad m√°xima
    try:
        profundidades = [nx.shortest_path_length(arbol, nodo_raiz, nodo) 
                        for nodo in arbol.nodes() if nodo != nodo_raiz]
        profundidad_maxima = max(profundidades) if profundidades else 0
        print(f"  - Profundidad m√°xima: {profundidad_maxima}")
    except:
        profundidad_maxima = 0
        print(f"  - Profundidad m√°xima: 0")
    
    # Encontrar hojas
    hojas = [nodo for nodo in arbol.nodes() if arbol.out_degree(nodo) == 0]
    print(f"  - Hojas del √°rbol ({len(hojas)}): {hojas}")
    
    # Encontrar nodos internos (no ra√≠z y no hoja)
    nodos_internos = [nodo for nodo in arbol.nodes() 
                     if nodo != nodo_raiz and arbol.out_degree(nodo) > 0]
    print(f"  - Nodos internos ({len(nodos_internos)}): {nodos_internos}")
    
    return profundidad_maxima, hojas, nodos_internos

def exportar_resultados_busqueda_limitada(arbol, configuracion, orden_bfs, orden_dfs, caminos_dfs, limite_bfs, limite_dfs):
    """
    Exporta los resultados de las b√∫squedas limitadas a archivos CSV
    """
    carpeta_salida = "resultados_busqueda_limitada"
    if not os.path.exists(carpeta_salida):
        os.makedirs(carpeta_salida)
    
    # Crear subcarpeta para la configuraci√≥n actual
    carpeta_config = os.path.join(carpeta_salida, configuracion)
    if not os.path.exists(carpeta_config):
        os.makedirs(carpeta_config)
    
    # Exportar resultados BFS limitada
    datos_bfs = []
    for i, nodo in enumerate(orden_bfs, 1):
        datos_bfs.append({
            'orden': i,
            'nodo': nodo,
            'grado_salida': arbol.out_degree(nodo),
            'grado_entrada': arbol.in_degree(nodo),
            'es_hoja': arbol.out_degree(nodo) == 0,
            'es_raiz': arbol.in_degree(nodo) == 0
        })
    
    df_bfs = pd.DataFrame(datos_bfs)
    ruta_bfs = os.path.join(carpeta_config, f"{configuracion}_bfs_limite_{limite_bfs}.csv")
    df_bfs.to_csv(ruta_bfs, index=False)
    print(f"‚úì Resultados BFS (limite {limite_bfs}) guardados: {ruta_bfs}")
    
    # Exportar resultados DFS limitada
    datos_dfs = []
    for i, nodo in enumerate(orden_dfs, 1):
        datos_dfs.append({
            'orden': i,
            'nodo': nodo,
            'grado_salida': arbol.out_degree(nodo),
            'grado_entrada': arbol.in_degree(nodo),
            'es_hoja': arbol.out_degree(nodo) == 0,
            'es_raiz': arbol.in_degree(nodo) == 0
        })
    
    df_dfs = pd.DataFrame(datos_dfs)
    ruta_dfs = os.path.join(carpeta_config, f"{configuracion}_dfs_limite_{limite_dfs}.csv")
    df_dfs.to_csv(ruta_dfs, index=False)
    print(f"‚úì Resultados DFS (limite {limite_dfs}) guardados: {ruta_dfs}")
    
    # Exportar caminos DFS completos (limitados)
    datos_caminos = []
    for i, camino in enumerate(caminos_dfs, 1):
        datos_caminos.append({
            'camino_id': i,
            'camino': ' ‚Üí '.join(camino),
            'longitud': len(camino) - 1,
            'nodo_inicio': camino[0],
            'nodo_fin': camino[-1],
            'niveles_recorridos': len(camino) - 1,
            'limite_aplicado': limite_dfs
        })
    
    df_caminos = pd.DataFrame(datos_caminos)
    ruta_caminos = os.path.join(carpeta_config, f"{configuracion}_caminos_dfs_limite_{limite_dfs}.csv")
    df_caminos.to_csv(ruta_caminos, index=False)
    print(f"‚úì Caminos DFS (limite {limite_dfs}) guardados: {ruta_caminos}")
    
    # Exportar resumen consolidado
    datos_resumen = {
        'configuracion': [configuracion],
        'limite_bfs': [limite_bfs],
        'limite_dfs': [limite_dfs],
        'nodos_visitados_bfs': [len(orden_bfs)],
        'nodos_visitados_dfs': [len(orden_dfs)],
        'caminos_dfs_encontrados': [len(caminos_dfs)],
        'nodos_total_arbol': [arbol.number_of_nodes()],
        'aristas_total_arbol': [arbol.number_of_edges()]
    }
    
    df_resumen = pd.DataFrame(datos_resumen)
    ruta_resumen = os.path.join(carpeta_config, f"{configuracion}_resumen_limites.csv")
    df_resumen.to_csv(ruta_resumen, index=False)
    print(f"‚úì Resumen consolidado guardado: {ruta_resumen}")
    
    return df_bfs, df_dfs, df_caminos, df_resumen

def exportar_variables_comunes(configuracion, variables_bfs, variables_dfs):
    """
    Exporta las variables comunes entre BFS y DFS, y sus diferencias
    """
    carpeta_salida = "resultados_busqueda_limitada"
    carpeta_config = os.path.join(carpeta_salida, configuracion)
    
    if not os.path.exists(carpeta_config):
        os.makedirs(carpeta_config)
    
    # Convertir a conjuntos para operaciones de conjunto
    set_bfs = set(variables_bfs)
    set_dfs = set(variables_dfs)
    
    # Encontrar variables comunes
    comunes = sorted(list(set_bfs.intersection(set_dfs)))
    
    # Encontrar variables √∫nicas en cada b√∫squeda
    unicas_bfs = sorted(list(set_bfs - set_dfs))
    unicas_dfs = sorted(list(set_dfs - set_bfs))
    
    # Crear DataFrames para cada conjunto
    df_comunes = pd.DataFrame(comunes, columns=['variables_comunes'])
    df_unicas_bfs = pd.DataFrame(unicas_bfs, columns=['variables_unicas_bfs'])
    df_unicas_dfs = pd.DataFrame(unicas_dfs, columns=['variables_unicas_dfs'])
    
    # Guardar archivos
    ruta_comunes = os.path.join(carpeta_config, f"{configuracion}_variables_comunes.csv")
    df_comunes.to_csv(ruta_comunes, index=False)
    print(f"‚úì Variables comunes guardadas: {ruta_comunes}")
    
    if unicas_bfs:
        ruta_unicas_bfs = os.path.join(carpeta_config, f"{configuracion}_variables_unicas_bfs.csv")
        df_unicas_bfs.to_csv(ruta_unicas_bfs, index=False)
        print(f"‚úì Variables √∫nicas BFS guardadas: {ruta_unicas_bfs}")
    
    if unicas_dfs:
        ruta_unicas_dfs = os.path.join(carpeta_config, f"{configuracion}_variables_unicas_dfs.csv")
        df_unicas_dfs.to_csv(ruta_unicas_dfs, index=False)
        print(f"‚úì Variables √∫nicas DFS guardadas: {ruta_unicas_dfs}")
    
    # Crear resumen de comparaci√≥n
    datos_comparacion = {
        'tipo_comparacion': ['Comunes', '√önicas BFS', '√önicas DFS', 'Total BFS', 'Total DFS'],
        'cantidad': [len(comunes), len(unicas_bfs), len(unicas_dfs), len(variables_bfs), len(variables_dfs)]
    }
    
    df_comparacion = pd.DataFrame(datos_comparacion)
    ruta_comparacion = os.path.join(carpeta_config, f"{configuracion}_comparacion_variables.csv")
    df_comparacion.to_csv(ruta_comparacion, index=False)
    print(f"‚úì Comparaci√≥n de variables guardada: {ruta_comparacion}")
    
    return df_comunes, df_unicas_bfs, df_unicas_dfs

def procesar_archivo_gml(ruta_archivo, limite_bfs=3, limite_dfs=3):
    """
    Procesa un archivo GML espec√≠fico con l√≠mites en las b√∫squedas
    """
    if not os.path.exists(ruta_archivo):
        print(f"‚ùå Error: No se encuentra el archivo {ruta_archivo}")
        return False
    
    # Cargar √°rbol enraizado
    arbol, nombre_grafo = cargar_arbol_enraizado(ruta_archivo)
    
    if arbol is None:
        return False
    
    # Extraer configuraci√≥n del nombre del archivo
    configuracion = extraer_configuracion_archivo(ruta_archivo)
    print(f"üîß Configuraci√≥n detectada: {configuracion}")
    print(f"üìè L√≠mites aplicados: BFS={limite_bfs} niveles, DFS={limite_dfs} niveles")
    
    # Encontrar nodo ra√≠z autom√°ticamente
    nodo_raiz = encontrar_nodo_raiz(arbol)
    print(f"üîç Nodo ra√≠z detectado: {nodo_raiz}")
    
    # Mostrar todos los nodos disponibles
    nodos = list(arbol.nodes())
    print(f"\nNODOS DISPONIBLES: {nodos}")
    
    # Realizar an√°lisis completo
    profundidad_maxima, hojas, nodos_internos = analizar_estructura_arbol(arbol, nodo_raiz)
    
    # Realizar b√∫squedas limitadas desde la ra√≠z
    print(f"\nüéØ Realizando b√∫squedas limitadas desde la ra√≠z: {nodo_raiz}")
    orden_bfs, niveles_bfs = busqueda_anchura_limitada(arbol, nodo_raiz, limite_bfs)
    orden_dfs, caminos_dfs = busqueda_profundidad_limitada(arbol, nodo_raiz, limite_dfs)
    
    # Exportar todos los resultados
    print(f"\nüíæ Exportando resultados limitados a CSV...")
    
    # Exportar resultados de b√∫squedas limitadas
    df_bfs, df_dfs, df_caminos, df_resumen = exportar_resultados_busqueda_limitada(
        arbol, configuracion, orden_bfs, orden_dfs, caminos_dfs, limite_bfs, limite_dfs
    )
    
    # Exportar comparaci√≥n de variables entre BFS y DFS
    df_comunes, df_unicas_bfs, df_unicas_dfs = exportar_variables_comunes(
        configuracion, orden_bfs, orden_dfs
    )
    
    # Resumen final
    print(f"\n" + "=" * 80)
    print(f"RESUMEN EJECUCI√ìN LIMITADA COMPLETADA - {configuracion}")
    print("=" * 80)
    print(f"üìä BFS (l√≠mite {limite_bfs}): {len(orden_bfs)} nodos visitados")
    print(f"üìä DFS (l√≠mite {limite_dfs}): {len(orden_dfs)} nodos visitados")
    print(f"üõ£Ô∏è  Caminos DFS encontrados: {len(caminos_dfs)}")
    print(f"ü§ù Variables comunes BFS/DFS: {len(set(orden_bfs).intersection(set(orden_dfs)))}")
    print(f"üìÅ Archivos CSV generados en: resultados_busqueda_limitada/{configuracion}/")
    print(f"üå≥ Ra√≠z del √°rbol: {nodo_raiz}")
    
    return True

def procesar_todas_configuraciones(profundidad="prof1", limite_bfs=3, limite_dfs=3):
    """
    Procesa todas las configuraciones (B2C, B4C, etc.) con l√≠mites espec√≠ficos
    """
    print("=" * 80)
    print(f"PROCESAMIENTO MASIVO CON L√çMITES")
    print(f"L√≠mite BFS: {limite_bfs} niveles | L√≠mite DFS: {limite_dfs} niveles")
    print("=" * 80)
    
    # Lista de todas las configuraciones a procesar
    configuraciones = ['B2C', 'B4C', 'B8C', 'B16C', 'W2C', 'W4C', 'W8C', 'W16C']
    
    resultados_totales = []
    archivos_procesados = []
    archivos_fallados = []
    
    for config in configuraciones:
        print(f"\n{'#' * 80}")
        print(f"PROCESANDO CONFIGURACI√ìN: {config}")
        print(f"{'#' * 80}")
        
        # Construir la ruta del archivo
        ruta_archivo = f"mst_raiz_reducido/arbol_reducido_{config}_{profundidad}.gml"
        
        # Verificar si el archivo existe
        if not os.path.exists(ruta_archivo):
            print(f"‚ö†Ô∏è  Advertencia: No se encuentra {ruta_archivo}")
            print(f"   Intentando formato alternativo...")
            # Intentar formato alternativo
            ruta_alternativa = f"mst_raiz_reducido/arbol_reducido_{config}_directa_target_y_prof{limite_bfs}.gml"
            if os.path.exists(ruta_alternativa):
                ruta_archivo = ruta_alternativa
                print(f"   ‚úì Usando archivo alternativo: {ruta_alternativa}")
            else:
                print(f"‚ùå No se encontr√≥ archivo para {config}")
                archivos_fallados.append(config)
                continue
        
        # Procesar el archivo
        exito = procesar_archivo_gml(ruta_archivo, limite_bfs, limite_dfs)
        
        if exito:
            archivos_procesados.append(config)
            resultados_totales.append({
                'configuracion': config,
                'estado': '√âXITO',
                'limite_bfs': limite_bfs,
                'limite_dfs': limite_dfs,
                'archivo': ruta_archivo
            })
        else:
            archivos_fallados.append(config)
            resultados_totales.append({
                'configuracion': config,
                'estado': 'FALL√ì',
                'limite_bfs': limite_bfs,
                'limite_dfs': limite_dfs,
                'archivo': ruta_archivo
            })
    
    # Generar resumen global
    generar_resumen_global(resultados_totales, limite_bfs, limite_dfs)
    
    return resultados_totales

def generar_resumen_global(resultados, limite_bfs, limite_dfs):
    """
    Genera un resumen global de todas las configuraciones procesadas
    """
    carpeta_salida = "resultados_busqueda_limitada"
    if not os.path.exists(carpeta_salida):
        os.makedirs(carpeta_salida)
    
    # Crear DataFrame con todos los resultados
    df_resumen_global = pd.DataFrame(resultados)
    
    # Agregar estad√≠sticas adicionales
    total_procesados = len([r for r in resultados if r['estado'] == '√âXITO'])
    total_fallados = len([r for r in resultados if r['estado'] == 'FALL√ì'])
    
    # Guardar resumen global
    ruta_resumen_global = os.path.join(carpeta_salida, f"resumen_global_limites_bfs{limite_bfs}_dfs{limite_dfs}.csv")
    df_resumen_global.to_csv(ruta_resumen_global, index=False)
    
    print(f"\n{'=' * 80}")
    print("RESUMEN GLOBAL DEL PROCESAMIENTO")
    print(f"{'=' * 80}")
    print(f"‚úÖ Configuraciones procesadas exitosamente: {total_procesados}")
    print(f"‚ùå Configuraciones falladas: {total_fallados}")
    print(f"üìä L√≠mites aplicados: BFS={limite_bfs}, DFS={limite_dfs}")
    print(f"üìÅ Resumen global guardado: {ruta_resumen_global}")
    
    # Mostrar lista de configuraciones procesadas
    if total_procesados > 0:
        print(f"\nüìã Configuraciones exitosas:")
        for resultado in resultados:
            if resultado['estado'] == '√âXITO':
                print(f"   ‚úì {resultado['configuracion']}")
    
    if total_fallados > 0:
        print(f"\n‚ö†Ô∏è  Configuraciones falladas:")
        for resultado in resultados:
            if resultado['estado'] == 'FALL√ì':
                print(f"   ‚úó {resultado['configuracion']}")

def main():
    """
    Funci√≥n principal para procesar todas las configuraciones con l√≠mites
    """
    print("=" * 80)
    print("B√öSQUEDA EN ANCHURA Y PROFUNDIDAD - CON L√çMITES")
    print("=" * 80)
    
    # CONFIGURACI√ìN DE L√çMITES (puedes modificar estos valores)
    LIMITE_BFS = 3  # Niveles m√°ximos para BFS
    LIMITE_DFS = 3  # Niveles m√°ximos para DFS
    PROFUNDIDAD_ARCHIVOS = "prof1"  # Puede ser "prof1", "prof2", "prof3", etc.
    
    print(f"‚öôÔ∏è  Configuraci√≥n de l√≠mites:")
    print(f"   - L√≠mite BFS: {LIMITE_BFS} niveles")
    print(f"   - L√≠mite DFS: {LIMITE_DFS} niveles")
    print(f"   - Profundidad de archivos: {PROFUNDIDAD_ARCHIVOS}")
    
    # Procesar todas las configuraciones
    resultados = procesar_todas_configuraciones(PROFUNDIDAD_ARCHIVOS, LIMITE_BFS, LIMITE_DFS)
    
    print(f"\n{'=' * 80}")
    print("PROCESAMIENTO COMPLETADO")
    print(f"{'=' * 80}")
    print("üéØ Los resultados se han guardado en la carpeta: resultados_busqueda_limitada/")
    print("üìÅ Cada configuraci√≥n tiene su propia subcarpeta con:")
    print("   - Resultados BFS limitados")
    print("   - Resultados DFS limitados")
    print("   - Caminos DFS limitados")
    print("   - Variables comunes y √∫nicas")
    print("   - Resumen de la ejecuci√≥n")

if __name__ == "__main__":
    # Ejecutar procesamiento principal
    main()